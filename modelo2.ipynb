{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['periodo', 'estu_tipodocumento', 'estu_consecutivo',\n",
      "       'cole_area_ubicacion', 'cole_bilingue', 'cole_calendario',\n",
      "       'cole_caracter', 'cole_cod_dane_establecimiento', 'cole_cod_dane_sede',\n",
      "       'cole_cod_depto_ubicacion', 'cole_cod_mcpio_ubicacion',\n",
      "       'cole_codigo_icfes', 'cole_depto_ubicacion', 'cole_genero',\n",
      "       'cole_jornada', 'cole_mcpio_ubicacion', 'cole_naturaleza',\n",
      "       'cole_nombre_establecimiento', 'cole_nombre_sede',\n",
      "       'cole_sede_principal', 'estu_cod_depto_presentacion',\n",
      "       'estu_cod_mcpio_presentacion', 'estu_cod_reside_depto',\n",
      "       'estu_cod_reside_mcpio', 'estu_depto_presentacion', 'estu_depto_reside',\n",
      "       'estu_estadoinvestigacion', 'estu_estudiante', 'estu_fechanacimiento',\n",
      "       'estu_genero', 'estu_mcpio_presentacion', 'estu_mcpio_reside',\n",
      "       'estu_nacionalidad', 'estu_pais_reside', 'estu_privado_libertad',\n",
      "       'fami_cuartoshogar', 'fami_educacionmadre', 'fami_educacionpadre',\n",
      "       'fami_estratovivienda', 'fami_personashogar', 'fami_tieneautomovil',\n",
      "       'fami_tienecomputador', 'fami_tieneinternet', 'fami_tienelavadora',\n",
      "       'desemp_ingles', 'punt_ingles', 'punt_matematicas',\n",
      "       'punt_sociales_ciudadanas', 'punt_c_naturales', 'punt_lectura_critica',\n",
      "       'punt_global'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"/Users/camilalopez/Downloads/icfes_resultados.csv\")\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos en la columna 'cole_caracter':\n",
      "['TÉCNICO/ACADÉMICO' 'ACADÉMICO' 'TÉCNICO' 'NO APLICA']\n",
      "\n",
      "Valores únicos en la columna 'cole_area_ubicacion':\n",
      "['URBANO' 'RURAL']\n",
      "\n",
      "Valores únicos en la columna 'cole_bilingue':\n",
      "['N' 'S']\n",
      "\n",
      "Valores únicos en la columna 'cole_calendario':\n",
      "['A' 'OTRO' 'B']\n",
      "\n",
      "Valores únicos en la columna 'cole_naturaleza':\n",
      "['OFICIAL' 'NO OFICIAL']\n",
      "\n",
      "Valores únicos en la columna 'cole_jornada':\n",
      "['MAÑANA' 'COMPLETA' 'SABATINA' 'TARDE' 'UNICA' 'NOCHE']\n",
      "\n",
      "Valores únicos en la columna 'cole_sede_principal':\n",
      "['S' 'N']\n",
      "\n",
      "Valores únicos en la columna 'cole_mcpio_ubicacion':\n",
      "['VILLAPINZÓN' 'SOACHA' 'CHÍA' 'ZIPAQUIRA' 'GIRARDOT' 'PASCA' 'CHIA'\n",
      " 'FACATATIVA' 'FUSAGASUGÁ' 'MADRID' 'LA MESA' 'GUADUAS' 'PUERTO SALGAR'\n",
      " 'PACHO' 'FUSAGASUGA' 'SOPÓ' 'MOSQUERA' 'SILVANIA' 'CACHIPAY' 'FUNZA'\n",
      " 'NIMAIMA' 'SAN ANTONIO DEL TEQUENDAMA' 'GACHALÁ' 'TABIO' 'FACATATIVÁ'\n",
      " 'VILLAPINZON' 'GACHETÁ' 'VILLETA' 'SAN FRANCISCO' 'CAJICÁ' 'COTA'\n",
      " 'VERGARA' 'AGUA DE DIOS' 'ANAPOIMA' 'MANTA' 'RAFAEL REYES (APULO)'\n",
      " 'LA VEGA' 'ZIPAQUIRÁ' 'YACOPI' 'JERUSALEN' 'EL PEÑÓN'\n",
      " 'SAN ANTONIO DE TEQUENDAMA' 'GUASCA' 'TIBACUY' 'APULO' 'LA CALERA'\n",
      " 'SAN BERNARDO' 'MACHETÁ' 'VIANÍ' 'VILLA DE SAN DIEGO DE UBATÉ' 'GUACHETÁ'\n",
      " 'UBATE' 'ANOLAIMA' 'SUESCA' 'VIOTA' 'TOCANCIPÁ' 'LENGUAZAQUE' 'SASAIMA'\n",
      " 'CHOCONTÁ' 'EL ROSAL' 'VIOTÁ' 'SESQUILE' 'FOMEQUE' 'SUBACHOQUE' 'FÓMEQUE'\n",
      " 'NEMOCÓN' 'ZIPACÓN' 'PARATEBUENO' 'TOPAIPÍ' 'EL PEÑON'\n",
      " 'GUAYABAL DE SÍQUIMA' 'COGUA' 'TENJO' 'YACOPÍ' 'LA PEÑA' 'UNE' 'GAMA'\n",
      " 'SIBATÉ' 'RICAURTE' 'LA PALMA' 'TIBIRITA' 'QUETAME' 'NOCAIMA' 'FÚQUENE'\n",
      " 'CAJICA' 'BELTRAN' 'TENA' 'GUTIÉRREZ' 'FUQUENE' 'QUIPILE' 'NEMOCON'\n",
      " 'SESQUILÉ' 'JUNÍN' 'EL COLEGIO' 'JUNIN' 'GUAYABETAL' 'SIMIJACA'\n",
      " 'CAPARRAPI' 'ARBELAEZ' 'CHOACHI' 'CHAGUANÍ' 'TOCANCIPA' 'CABRERA'\n",
      " 'ZIPACON' 'PANDI' 'BELTRÁN' 'ARBELÁEZ' 'VILLAGÓMEZ' 'CARMEN DE CARUPA'\n",
      " 'GACHETA' 'CÁQUEZA' 'CAQUEZA' 'JERUSALÉN' 'GUACHETA' 'GRANADA'\n",
      " 'GACHANCIPÁ' 'CHOCONTA' 'TOCAIMA' 'SIBATE' 'MACHETA' 'CHOACHÍ' 'CHIPAQUE'\n",
      " 'GACHALA' 'SUTATAUSA' 'CUCUNUBA' 'CAPARRAPÍ' 'CUCUNUBÁ' 'GUTIERREZ'\n",
      " 'QUEBRADANEGRA' 'PAIME' 'BOJACÁ' 'VIANI' 'TAUSA' 'UBALA'\n",
      " 'SAN JUAN DE RIO SECO' 'SUSA' 'NILO' 'UTICA' 'ÚTICA'\n",
      " 'GUAYABAL DE SIQUIMA' 'SAN CAYETANO' 'GACHANCIPA' 'SUPATÁ' 'FOSCA'\n",
      " 'SAN JUAN DE RIOSECO' 'SOPO' 'VILLAGOMEZ' 'GUATAQUI'\n",
      " 'VENECIA (OSPINA PEREZ)' 'VENECIA' 'UBALÁ' 'MEDINA' 'UBAQUE' 'NARIÑO'\n",
      " 'ALBAN' 'GUATAVITA' 'SUPATA' 'TOPAIPI' 'CHAGUANI' 'BITUIMA' 'ALBÁN'\n",
      " 'PULÍ' 'GUATAQUÍ' 'PULI']\n",
      "\n",
      "Valores únicos en la columna 'punt_matematicas':\n",
      "[ 28.    43.    68.    52.    44.    47.    38.    39.    63.    58.\n",
      "  57.    48.17  41.    54.    48.    37.    32.    42.    64.    53.\n",
      "  50.82  50.    51.    49.    42.46  55.89  45.    48.09  46.    55.\n",
      "  56.    63.02  34.    62.    35.    66.    72.05  60.    71.    69.\n",
      "  30.    18.    65.    55.62  67.    59.    31.    33.    45.38  78.\n",
      "  25.02  53.37  38.64  60.91  60.51  74.    24.    61.    77.    40.\n",
      "  42.4   36.    76.53  50.67   6.    27.    29.    58.38  26.    43.99\n",
      "  31.19  39.25  25.    72.11  70.    73.    63.5   93.    75.    65.93\n",
      "  72.63  35.39  49.55  30.9   23.    53.16  84.    78.36  69.01  75.41\n",
      "  58.05  83.    71.35  65.63  79.    35.59  71.12  76.    80.    59.94\n",
      "  66.17  39.12  49.43  72.     0.    57.47  74.62 100.    41.82  57.53\n",
      "  81.    94.    62.98  52.17  76.37  51.97  87.    52.32  65.27  85.\n",
      "  15.    57.27  35.55  35.78  15.67  44.39  47.3   62.72  65.46  22.\n",
      "  54.52  28.91  47.19  68.39  92.    97.    49.52  36.11  54.67  82.\n",
      "  44.55  49.77  17.    16.    62.48  37.56  82.87  40.78  99.    41.69\n",
      "  83.87  54.74  46.77  37.36  32.75  99.48  25.39  38.84  54.94  65.19\n",
      "  62.56  72.36  46.84  89.    20.    40.93  47.01   7.    44.69  59.93\n",
      "  12.    81.47  69.03  57.34  86.    19.    21.    57.29   5.    95.\n",
      "  46.86  60.2   54.77  13.    88.    79.26 113.27  28.27  97.02  52.11\n",
      "  41.51  97.66  81.17  72.53  65.86  96.    39.16  49.85  68.11  71.05\n",
      " 114.    23.61  32.15  32.42 102.    82.15  74.38  28.52  68.62  38.94\n",
      "  28.58  90.    29.11  59.86  52.39  43.88  87.61  76.65  65.67 107.\n",
      "  88.79 101.    89.92  24.3   62.53  44.23  59.77  60.14  62.92  69.12\n",
      "  49.57  91.    87.43  74.33  35.84  87.14  57.11  33.72 112.99 103.94\n",
      "  68.85  98.    23.97  68.03  54.88  33.46  16.12   1.    97.5   81.33\n",
      "  98.19  87.15 127.    28.78  11.    76.1  125.     8.   106.    93.8\n",
      "  13.38  18.23 104.09 108.    23.04  23.84  80.88  17.5   87.76  77.98\n",
      "   8.57 126.    93.69  82.16 113.64 113.48 116.   114.88 103.    22.65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2883925508.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Supongamos que 'data' es tu DataFrame que contiene la base de datos\n",
    "\n",
    "# Seleccionar las variables de interés\n",
    "variables_interes = ['cole_caracter', 'cole_area_ubicacion', 'cole_bilingue', \n",
    "                     'cole_calendario', 'cole_naturaleza', 'cole_jornada', \n",
    "                     'cole_sede_principal', \n",
    "                     'cole_mcpio_ubicacion', 'punt_matematicas']\n",
    "\n",
    "# Crear un nuevo DataFrame con solo las variables de interés\n",
    "df1 = df[variables_interes]\n",
    "\n",
    "df1.dropna(inplace=True)\n",
    "# Verificar los valores únicos en cada columna categórica\n",
    "for column in df1:\n",
    "    if column in df1.columns:\n",
    "        print(f\"\\nValores únicos en la columna '{column}':\")\n",
    "        print(df1[column].unique())\n",
    "    else:\n",
    "        print(f\"\\nLa columna '{column}' no está presente en el DataFrame.\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_caracter'] = df1['cole_caracter'].map(mapeo_cole_caracter)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_area_ubicacion'] = df1['cole_area_ubicacion'].map(mapeo_cole_area_ubicacion)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_bilingue'] = df1['cole_bilingue'].map(mapeo_cole_bilingue)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_calendario'] = df1['cole_calendario'].map(mapeo_cole_calendario)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_naturaleza'] = df1['cole_naturaleza'].map(mapeo_cole_naturaleza)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_jornada'] = df1['cole_jornada'].map(mapeo_cole_jornada)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_sede_principal'] = df1['cole_sede_principal'].map(mapeo_cole_sede_principal)\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_mcpio_ubicacion'] = df1['cole_mcpio_ubicacion'].astype('category')\n",
      "/var/folders/wg/knznwbyd1250g3nq6hknkh8w0000gn/T/ipykernel_4279/2536966785.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['cole_mcpio_ubicacion'] = df1['cole_mcpio_ubicacion'].cat.codes + 1\n"
     ]
    }
   ],
   "source": [
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_caracter = {\n",
    "    'ACADÉMICO': 1,\n",
    "    'TÉCNICO/ACADÉMICO': 2,\n",
    "    'TÉCNICO': 3,\n",
    "    'NO APLICA': 4\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_caracter' utilizando el método map\n",
    "df1['cole_caracter'] = df1['cole_caracter'].map(mapeo_cole_caracter)\n",
    "\n",
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_area_ubicacion = {\n",
    "    'URBANO': 1,\n",
    "    'RURAL': 2\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_area_ubicacion' utilizando el método map\n",
    "df1['cole_area_ubicacion'] = df1['cole_area_ubicacion'].map(mapeo_cole_area_ubicacion)\n",
    "\n",
    "\n",
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_bilingue = {\n",
    "    'N': 0,\n",
    "    'S': 1\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_bilingue' utilizando el método map\n",
    "df1['cole_bilingue'] = df1['cole_bilingue'].map(mapeo_cole_bilingue)\n",
    "\n",
    "\n",
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_calendario = {\n",
    "    'A': 1,\n",
    "    'B': 2,\n",
    "    'OTRO': 3\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_calendario' utilizando el método map\n",
    "df1['cole_calendario'] = df1['cole_calendario'].map(mapeo_cole_calendario)\n",
    "\n",
    "\n",
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_naturaleza = {\n",
    "    'NO OFICIAL': 0,\n",
    "    'OFICIAL': 1\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_naturaleza' utilizando el método map\n",
    "df1['cole_naturaleza'] = df1['cole_naturaleza'].map(mapeo_cole_naturaleza)\n",
    "\n",
    "\n",
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_jornada = {\n",
    "    'SABATINA': 1,\n",
    "    'COMPLETA': 2,\n",
    "    'MAÑANA': 3,\n",
    "    'TARDE': 4,\n",
    "    'UNICA': 5,\n",
    "    'NOCHE': 6\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_jornada' utilizando el método map\n",
    "df1['cole_jornada'] = df1['cole_jornada'].map(mapeo_cole_jornada)\n",
    "\n",
    "\n",
    "# Definir un diccionario de mapeo\n",
    "mapeo_cole_sede_principal = {\n",
    "    'S': 1,\n",
    "    'N': 0\n",
    "}\n",
    "\n",
    "# Asignar valores numéricos a la columna 'cole_sede_principal' utilizando el método map\n",
    "df1['cole_sede_principal'] = df1['cole_sede_principal'].map(mapeo_cole_sede_principal)\n",
    "\n",
    "\n",
    "# Convertir la columna 'cole_mcpio_ubicacion' en una serie categórica\n",
    "df1['cole_mcpio_ubicacion'] = df1['cole_mcpio_ubicacion'].astype('category')\n",
    "\n",
    "# Asignar valores numéricos secuenciales a los municipios\n",
    "df1['cole_mcpio_ubicacion'] = df1['cole_mcpio_ubicacion'].cat.codes + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = df1\n",
    "\n",
    "y = df1['punt_matematicas']\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir los datos en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento (70%) y validación (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0109\n",
      "Epoch [2/50], Loss: 0.0159\n",
      "Epoch [3/50], Loss: 0.0304\n",
      "Epoch [4/50], Loss: 0.0190\n",
      "Epoch [5/50], Loss: 0.0081\n",
      "Epoch [6/50], Loss: 0.0071\n",
      "Epoch [7/50], Loss: 0.0060\n",
      "Epoch [8/50], Loss: 0.0047\n",
      "Epoch [9/50], Loss: 0.0083\n",
      "Epoch [10/50], Loss: 0.0014\n",
      "Epoch [11/50], Loss: 0.0008\n",
      "Epoch [12/50], Loss: 0.0154\n",
      "Epoch [13/50], Loss: 0.0024\n",
      "Epoch [14/50], Loss: 0.0042\n",
      "Epoch [15/50], Loss: 0.0035\n",
      "Epoch [16/50], Loss: 0.0035\n",
      "Epoch [17/50], Loss: 0.0030\n",
      "Epoch [18/50], Loss: 0.0017\n",
      "Epoch [19/50], Loss: 0.0033\n",
      "Epoch [20/50], Loss: 0.0031\n",
      "Epoch [21/50], Loss: 0.0051\n",
      "Epoch [22/50], Loss: 0.0024\n",
      "Epoch [23/50], Loss: 0.0040\n",
      "Epoch [24/50], Loss: 0.0019\n",
      "Epoch [25/50], Loss: 0.0002\n",
      "Epoch [26/50], Loss: 0.0019\n",
      "Epoch [27/50], Loss: 0.0021\n",
      "Epoch [28/50], Loss: 0.0018\n",
      "Epoch [29/50], Loss: 0.0008\n",
      "Epoch [30/50], Loss: 0.0002\n",
      "Epoch [31/50], Loss: 0.0006\n",
      "Epoch [32/50], Loss: 0.0019\n",
      "Epoch [33/50], Loss: 0.0041\n",
      "Epoch [34/50], Loss: 0.0036\n",
      "Epoch [35/50], Loss: 0.0036\n",
      "Epoch [36/50], Loss: 0.0020\n",
      "Epoch [37/50], Loss: 0.0025\n",
      "Epoch [38/50], Loss: 0.0042\n",
      "Epoch [39/50], Loss: 0.0015\n",
      "Epoch [40/50], Loss: 0.0027\n",
      "Epoch [41/50], Loss: 0.0019\n",
      "Epoch [42/50], Loss: 0.0023\n",
      "Epoch [43/50], Loss: 0.0031\n",
      "Epoch [44/50], Loss: 0.0041\n",
      "Epoch [45/50], Loss: 0.0024\n",
      "Epoch [46/50], Loss: 0.0026\n",
      "Epoch [47/50], Loss: 0.0015\n",
      "Epoch [48/50], Loss: 0.0020\n",
      "Epoch [49/50], Loss: 0.0038\n",
      "Epoch [50/50], Loss: 0.0021\n",
      "Mean Squared Error on Test Set: 0.0035232272930443287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Normalizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convertir los datos a formato numpy\n",
    "X_train_np = np.array(X_train, dtype=np.float32)\n",
    "y_train_np = np.array(y_train, dtype=np.float32)\n",
    "X_test_np = np.array(X_test, dtype=np.float32)\n",
    "y_test_np = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "# Convertir los datos a tensores de PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "# Definir el modelo de regresión utilizando PyTorch\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "input_dim = X_train.shape[1]\n",
    "model_regression = RegressionModel(input_dim)\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_regression.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Entrenar el modelo\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(X_train_tensor), batch_size):\n",
    "        inputs = X_train_tensor[i:i+batch_size]\n",
    "        labels = y_train_tensor[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_regression(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model_regression(X_test_tensor)\n",
    "    test_loss = criterion(y_pred_tensor, y_test_tensor)\n",
    "    print(\"Mean Squared Error on Test Set:\", test_loss.item())\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.0035232272930443287\n",
      "Mean Absolute Error on Test Set: 0.040244643\n",
      "R^2 Score on Test Set: 0.9999721197239128\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Convertir las predicciones y las etiquetas de PyTorch a numpy arrays\n",
    "y_pred_np = y_pred_tensor.numpy()\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "\n",
    "# Calcular el Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test_np, y_pred_np)\n",
    "\n",
    "# Calcular el R^2 Score\n",
    "r2 = r2_score(y_test_np, y_pred_np)\n",
    "\n",
    "print(\"Mean Squared Error on Test Set:\", test_loss.item())\n",
    "print(\"Mean Absolute Error on Test Set:\", mae)\n",
    "print(\"R^2 Score on Test Set:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo en un archivo\n",
    "joblib.dump(model_regression, 'modelo_regresion_lineal2.pkl')\n",
    "# Cargar el modelo desde el archivo\n",
    "modelo_cargado = joblib.load('modelo_regresion_lineal2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler2.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "\n",
    "# Guardar el estado del modelo\n",
    "torch.save(model_regression.state_dict(), 'modelo_regresion2.pth')\n",
    "\n",
    "# Guardar el escalador\n",
    "joblib.dump(scaler, 'scaler2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 0.0035232272930443287\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definir la clase RegressionModel (debe ser igual a la que usaste para entrenar)\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Cargar el escalador\n",
    "scaler = joblib.load('scaler2.pkl')\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "input_dim = X_train.shape[1]  # Debes definir X_train o conocer su dimensión\n",
    "model_regression = RegressionModel(input_dim)\n",
    "\n",
    "# Cargar el estado del modelo\n",
    "model_regression.load_state_dict(torch.load('modelo_regresion2.pth'))\n",
    "model_regression.eval()  # Poner el modelo en modo de evaluación\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model_regression(X_test_tensor)\n",
    "    test_loss = criterion(y_pred_tensor, y_test_tensor)\n",
    "    print(\"Mean Squared Error on Test Set:\", test_loss.item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
